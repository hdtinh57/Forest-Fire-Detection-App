# ğŸ”¥ BÃO CÃO Äá»€ TÃ€I: Há»† THá»NG PHÃT HIá»†N CHÃY Rá»ªNG
## MÃ´n há»c: Xá»­ lÃ½ áº¢nh vÃ  Video (IVP501)

---

## ğŸ“‹ THÃ”NG TIN Äá»€ TÃ€I

| ThÃ´ng tin | Chi tiáº¿t |
|-----------|----------|
| **TÃªn Ä‘á» tÃ i** | Há»‡ thá»‘ng phÃ¡t hiá»‡n chÃ¡y rá»«ng thá»i gian thá»±c sá»­ dá»¥ng Deep Learning |
| **MÃ´ hÃ¬nh** | YOLOv11 Classification |
| **Framework** | Ultralytics, FastAPI, Streamlit |
| **NgÃ´n ngá»¯** | Python 3.11 |

---

## ğŸ“– Má»¤C Lá»¤C

1. [Giá»›i thiá»‡u](#1-giá»›i-thiá»‡u)
2. [Kiáº¿n trÃºc há»‡ thá»‘ng](#2-kiáº¿n-trÃºc-há»‡-thá»‘ng)
3. [Xá»­ lÃ½ áº£nh Ä‘áº§u vÃ o (Preprocessing)](#3-xá»­-lÃ½-áº£nh-Ä‘áº§u-vÃ o-preprocessing)
4. [Data Augmentation trong Training](#4-data-augmentation-trong-training)
5. [MÃ´ hÃ¬nh YOLO11 Classification](#5-mÃ´-hÃ¬nh-yolo11-classification)
6. [Káº¿t quáº£ Training](#6-káº¿t-quáº£-training)
7. [á»¨ng dá»¥ng Web](#7-á»©ng-dá»¥ng-web)
8. [Káº¿t luáº­n](#8-káº¿t-luáº­n)

---

## 1. GIá»šI THIá»†U

### 1.1 BÃ i toÃ¡n
PhÃ¡t hiá»‡n chÃ¡y rá»«ng sá»›m lÃ  má»™t váº¥n Ä‘á» quan trá»ng trong viá»‡c báº£o vá»‡ mÃ´i trÆ°á»ng vÃ  tÃ i sáº£n. Há»‡ thá»‘ng nÃ y sá»­ dá»¥ng **Computer Vision** vÃ  **Deep Learning** Ä‘á»ƒ phÃ¢n loáº¡i áº£nh/video thÃ nh hai lá»›p:
- **FIRE**: CÃ³ lá»­a/chÃ¡y
- **NON-FIRE**: KhÃ´ng cÃ³ lá»­a

### 1.2 Má»¥c tiÃªu
- XÃ¢y dá»±ng pipeline xá»­ lÃ½ áº£nh hoÃ n chá»‰nh
- Train mÃ´ hÃ¬nh YOLO11 Classification Ä‘áº¡t accuracy > 95%
- PhÃ¡t triá»ƒn á»©ng dá»¥ng web demo real-time
- Tá»‘i Æ°u hiá»‡u nÄƒng vá»›i WebSocket streaming

---

## 2. KIáº¾N TRÃšC Há»† THá»NG

### 2.1 SÆ¡ Ä‘á»“ tá»•ng quan

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        INPUT                                     â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚    â”‚  Image   â”‚    â”‚  Video   â”‚    â”‚  Camera  â”‚                â”‚
â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                         â–¼                                        â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚    â”‚           PREPROCESSING MODULE                       â”‚      â”‚
â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚      â”‚
â”‚    â”‚  â”‚ Denoise     â”‚â†’ â”‚ White       â”‚â†’ â”‚ CLAHE       â”‚ â”‚      â”‚
â”‚    â”‚  â”‚ (NLMeans)   â”‚  â”‚ Balance     â”‚  â”‚ Contrast    â”‚ â”‚      â”‚
â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚      â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                              â–¼                                   â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚    â”‚              YOLO11 CLASSIFICATION                    â”‚      â”‚
â”‚    â”‚                                                       â”‚      â”‚
â”‚    â”‚  Input: 224x224 RGB                                  â”‚      â”‚
â”‚    â”‚  Architecture: 47 layers, 1.5M params               â”‚      â”‚
â”‚    â”‚  Output: [FIRE, NON-FIRE] + Confidence              â”‚      â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                              â–¼                                   â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚    â”‚                    OUTPUT                             â”‚      â”‚
â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚      â”‚
â”‚    â”‚  â”‚ Prediction  â”‚  â”‚ Confidence  â”‚  â”‚ Alert       â”‚ â”‚      â”‚
â”‚    â”‚  â”‚ FIRE/NOFIRE â”‚  â”‚ 0.0 - 1.0   â”‚  â”‚ System      â”‚ â”‚      â”‚
â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚      â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Cáº¥u trÃºc thÆ° má»¥c

```
project/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ backend/                 # FastAPI Server
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ detection.py     # API phÃ¡t hiá»‡n áº£nh/video
â”‚   â”‚   â”‚   â””â”€â”€ websocket.py     # WebSocket streaming
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ detection.py     # YOLO inference
â”‚   â”‚   â”‚   â”œâ”€â”€ preprocessing.py # Tiá»n xá»­ lÃ½ áº£nh
â”‚   â”‚   â”‚   â””â”€â”€ websocket_stream.py
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”œâ”€â”€ frontend/                # Streamlit UI
â”‚   â”‚   â””â”€â”€ app.py
â”‚   â””â”€â”€ weights/
â”‚       â””â”€â”€ best.pt              # Model weights
â”œâ”€â”€ MyFireProject/               # Training results
â”‚   â””â”€â”€ yolo11n_fire_run5/
â”‚       â”œâ”€â”€ args.yaml            # Training config
â”‚       â”œâ”€â”€ weights/best.pt      # Best model
â”‚       â””â”€â”€ results.csv          # Training metrics
â”œâ”€â”€ processed_dataset/           # Dataset
â”‚   â”œâ”€â”€ train/                   # 4000 images
â”‚   â”œâ”€â”€ val/                     # 1000 images
â”‚   â””â”€â”€ test/                    # 50 images
â””â”€â”€ REPORT.md                    # File nÃ y
```

---

## 3. Xá»¬ LÃ áº¢NH Äáº¦U VÃ€O (PREPROCESSING)

### 3.1 Pipeline Tiá»n Xá»­ LÃ½

```
Input Image â†’ White Balance â†’ Denoise â†’ CLAHE â†’ Output
```

### 3.2 CÃ¡c ká»¹ thuáº­t Ä‘Æ°á»£c sá»­ dá»¥ng

#### 3.2.1 Khá»­ nhiá»…u - Non-Local Means Denoising

**CÃ´ng thá»©c toÃ¡n há»c:**

$$\hat{I}(x) = \frac{1}{C(x)} \sum_{y \in \Omega} w(x,y) \cdot I(y)$$

Trong Ä‘Ã³:
- $\hat{I}(x)$: GiÃ¡ trá»‹ pixel sau khi khá»­ nhiá»…u
- $I(y)$: GiÃ¡ trá»‹ pixel gá»‘c
- $w(x,y)$: Trá»ng sá»‘ dá»±a trÃªn Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng cá»§a patch
- $C(x)$: Há»‡ sá»‘ chuáº©n hÃ³a

**Trá»ng sá»‘ Ä‘Æ°á»£c tÃ­nh:**

$$w(x,y) = e^{-\frac{\|P(x) - P(y)\|^2}{h^2}}$$

- $P(x), P(y)$: CÃ¡c patch xung quanh pixel x vÃ  y
- $h$: Tham sá»‘ Ä‘iá»u khiá»ƒn cÆ°á»ng Ä‘á»™ khá»­ nhiá»…u

**Code implementation:**
```python
def denoise(self, image: np.ndarray) -> np.ndarray:
    return cv2.fastNlMeansDenoisingColored(
        image,
        None,
        h=self.denoise_strength,           # h = 10 (default)
        hForColorComponents=self.denoise_strength,
        templateWindowSize=7,               # KÃ­ch thÆ°á»›c patch
        searchWindowSize=21                 # VÃ¹ng tÃ¬m kiáº¿m
    )
```

**Æ¯u Ä‘iá»ƒm:**
- Giá»¯ Ä‘Æ°á»£c cáº¡nh sáº¯c nÃ©t
- Hiá»‡u quáº£ vá»›i nhiá»…u Gaussian
- PhÃ¹ há»£p cho áº£nh tá»± nhiÃªn

---

#### 3.2.2 CÃ¢n báº±ng tráº¯ng - Gray World Algorithm

**Giáº£ thiáº¿t:** Trung bÃ¬nh cá»§a táº¥t cáº£ mÃ u trong áº£nh tá»± nhiÃªn nÃªn lÃ  mÃ u xÃ¡m trung tÃ­nh.

**Thuáº­t toÃ¡n:**

1. TÃ­nh trung bÃ¬nh cá»§a má»—i kÃªnh mÃ u:
   - $\mu_R = \frac{1}{N}\sum R_i$
   - $\mu_G = \frac{1}{N}\sum G_i$
   - $\mu_B = \frac{1}{N}\sum B_i$

2. TÃ­nh trung bÃ¬nh tá»•ng: $\mu = \frac{\mu_R + \mu_G + \mu_B}{3}$

3. Scale má»—i kÃªnh:
   - $R' = R \times \frac{\mu}{\mu_R}$
   - $G' = G \times \frac{\mu}{\mu_G}$
   - $B' = B \times \frac{\mu}{\mu_B}$

**Code implementation:**
```python
def auto_white_balance(self, image: np.ndarray) -> np.ndarray:
    result = image.copy().astype(np.float32)
    
    avg_b = np.mean(result[:, :, 0])
    avg_g = np.mean(result[:, :, 1])
    avg_r = np.mean(result[:, :, 2])
    
    avg = (avg_b + avg_g + avg_r) / 3
    
    result[:, :, 0] = result[:, :, 0] * (avg / avg_b)
    result[:, :, 1] = result[:, :, 1] * (avg / avg_g)
    result[:, :, 2] = result[:, :, 2] * (avg / avg_r)
    
    return np.clip(result, 0, 255).astype(np.uint8)
```

---

#### 3.2.3 CLAHE - Contrast Limited Adaptive Histogram Equalization

**Váº¥n Ä‘á» vá»›i Histogram Equalization thÃ´ng thÆ°á»ng:**
- TÄƒng nhiá»…u trong vÃ¹ng Ä‘á»“ng nháº¥t
- KhÃ´ng thÃ­ch á»©ng vá»›i cÃ¡c vÃ¹ng khÃ¡c nhau cá»§a áº£nh

**Giáº£i phÃ¡p CLAHE:**

1. **Chia áº£nh thÃ nh cÃ¡c tile** (8x8 grid máº·c Ä‘á»‹nh)
2. **Ãp dá»¥ng histogram equalization** cho tá»«ng tile
3. **Giá»›i háº¡n contrast** (clip limit) Ä‘á»ƒ trÃ¡nh over-amplification
4. **Bilinear interpolation** Ä‘á»ƒ loáº¡i bá» artifacts á»Ÿ biÃªn

**CÃ´ng thá»©c Histogram Equalization:**

$$s_k = (L-1) \sum_{j=0}^{k} p_r(r_j)$$

Trong Ä‘Ã³:
- $s_k$: GiÃ¡ trá»‹ output
- $L$: Sá»‘ má»©c xÃ¡m (256)
- $p_r(r_j)$: XÃ¡c suáº¥t cá»§a má»©c xÃ¡m $r_j$

**Code implementation:**
```python
def enhance_contrast_clahe(self, image: np.ndarray) -> np.ndarray:
    # Chuyá»ƒn sang khÃ´ng gian LAB
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    
    # TÃ¡ch cÃ¡c kÃªnh L, A, B
    l, a, b = cv2.split(lab)
    
    # Ãp dá»¥ng CLAHE chá»‰ trÃªn kÃªnh L (Lightness)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l_enhanced = clahe.apply(l)
    
    # GhÃ©p láº¡i vÃ  chuyá»ƒn vá» BGR
    lab_enhanced = cv2.merge([l_enhanced, a, b])
    return cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)
```

**Tham sá»‘:**
- `clipLimit = 2.0`: Giá»›i háº¡n tÄƒng contrast
- `tileGridSize = (8, 8)`: Sá»‘ tile theo má»—i chiá»u

---

#### 3.2.4 Bilateral Filter (Khá»­ nhiá»…u giá»¯ cáº¡nh)

**CÃ´ng thá»©c:**

$$I^{filtered}(x) = \frac{1}{W_p} \sum_{x_i \in \Omega} I(x_i) \cdot f_r(\|I(x_i) - I(x)\|) \cdot g_s(\|x_i - x\|)$$

Trong Ä‘Ã³:
- $f_r$: Range filter (domain of intensity)
- $g_s$: Spatial filter (domain of space)
- $W_p$: Normalization factor

**Äáº·c Ä‘iá»ƒm:**
- Káº¿t há»£p **domain filter** vÃ  **range filter**
- LÃ m má»‹n vÃ¹ng Ä‘á»“ng nháº¥t
- Giá»¯ nguyÃªn cáº¡nh sáº¯c

---

## 4. DATA AUGMENTATION TRONG TRAINING

### 4.1 Cáº¥u hÃ¬nh Training (args.yaml)

Dá»±a trÃªn file `MyFireProject/yolo11n_fire_run5/args.yaml`:

```yaml
# === Cáº¤U HÃŒNH CÆ  Báº¢N ===
task: classify
model: yolo11n-cls.pt
epochs: 30
batch: 32
imgsz: 224                # KÃ­ch thÆ°á»›c áº£nh Ä‘áº§u vÃ o

# === AUGMENTATION PARAMETERS ===
hsv_h: 0.015              # Biáº¿n Ä‘á»•i Hue (Â±1.5%)
hsv_s: 0.7                # Biáº¿n Ä‘á»•i Saturation (Â±70%)
hsv_v: 0.4                # Biáº¿n Ä‘á»•i Value (Â±40%)
degrees: 0.0              # Xoay áº£nh (Ä‘á»™)
translate: 0.1            # Dá»‹ch chuyá»ƒn (Â±10%)
scale: 0.5                # Scale (Â±50%)
shear: 0.0                # Biáº¿n dáº¡ng shear
perspective: 0.0          # Biáº¿n dáº¡ng phá»‘i cáº£nh
flipud: 0.0               # Láº­t dá»c (0%)
fliplr: 0.5               # Láº­t ngang (50%)
mosaic: 1.0               # Mosaic augmentation (100%)
mixup: 0.0                # MixUp augmentation
auto_augment: randaugment # Auto augmentation strategy
erasing: 0.4              # Random erasing (40%)
```

### 4.2 Chi tiáº¿t cÃ¡c ká»¹ thuáº­t Augmentation

#### 4.2.1 HSV Augmentation

**Má»¥c Ä‘Ã­ch:** Thay Ä‘á»•i mÃ u sáº¯c Ä‘á»ƒ model robust vá»›i Ä‘iá»u kiá»‡n Ã¡nh sÃ¡ng khÃ¡c nhau.

**CÃ´ng thá»©c:**
- **Hue shift:** $H' = (H + \Delta h \times 180) \mod 180$, vá»›i $\Delta h \in [-0.015, 0.015]$
- **Saturation:** $S' = S \times (1 + \Delta s)$, vá»›i $\Delta s \in [-0.7, 0.7]$
- **Value:** $V' = V \times (1 + \Delta v)$, vá»›i $\Delta v \in [-0.4, 0.4]$

**Ã nghÄ©a cho Fire Detection:**
- Lá»­a cÃ³ mÃ u sáº¯c Ä‘a dáº¡ng (cam, Ä‘á», vÃ ng)
- Biáº¿n Ä‘á»•i HSV giÃºp model nháº­n diá»‡n cÃ¡c mÃ u lá»­a khÃ¡c nhau
- `hsv_v: 0.4` quan trá»ng vÃ¬ lá»­a cÃ³ thá»ƒ sÃ¡ng/tá»‘i khÃ¡c nhau

#### 4.2.2 Geometric Augmentation

| Tham sá»‘ | GiÃ¡ trá»‹ | Ã nghÄ©a |
|---------|---------|---------|
| `translate` | 0.1 | Dá»‹ch chuyá»ƒn Â±10% theo má»—i chiá»u |
| `scale` | 0.5 | Scale tá»« 50% Ä‘áº¿n 150% |
| `fliplr` | 0.5 | 50% xÃ¡c suáº¥t láº­t ngang |

**LÃ½ do chá»n:**
- `scale: 0.5` quan trá»ng vÃ¬ lá»­a cÃ³ thá»ƒ xuáº¥t hiá»‡n á»Ÿ nhiá»u kÃ­ch thÆ°á»›c
- `fliplr: 0.5` tÄƒng Ä‘a dáº¡ng dá»¯ liá»‡u
- `degrees: 0.0` vÃ¬ lá»­a thÆ°á»ng hÆ°á»›ng lÃªn trÃªn

#### 4.2.3 Mosaic Augmentation

**CÃ¡ch hoáº¡t Ä‘á»™ng:**
1. Láº¥y 4 áº£nh ngáº«u nhiÃªn tá»« dataset
2. GhÃ©p thÃ nh 1 áº£nh 2x2
3. Random crop Ä‘á»ƒ cÃ³ kÃ­ch thÆ°á»›c mong muá»‘n

**Æ¯u Ä‘iá»ƒm:**
- TÄƒng context Ä‘a dáº¡ng
- Hiá»‡u quáº£ batch normalization (nhiá»u object trong 1 áº£nh)
- Giáº£m overfitting

**Cáº¥u hÃ¬nh:** `mosaic: 1.0` â†’ 100% batch sá»­ dá»¥ng mosaic

#### 4.2.4 RandAugment

**`auto_augment: randaugment`** Ã¡p dá»¥ng chuá»—i cÃ¡c augmentation ngáº«u nhiÃªn.

**CÃ¡c phÃ©p biáº¿n Ä‘á»•i cÃ³ thá»ƒ:**
- AutoContrast
- Equalize
- Invert
- Rotate
- Posterize
- Solarize
- Color jittering
- Sharpness

#### 4.2.5 Random Erasing

**`erasing: 0.4`** â†’ 40% áº£nh bá»‹ xÃ³a ngáº«u nhiÃªn má»™t pháº§n.

**CÃ´ng dá»¥ng:**
- GiÃºp model khÃ´ng phá»¥ thuá»™c vÃ o má»™t vÃ¹ng cá»¥ thá»ƒ
- TÄƒng robustness vá»›i occlusion
- Regularization effect

---

## 5. MÃ” HÃŒNH YOLO11 CLASSIFICATION

### 5.1 Kiáº¿n trÃºc

```
YOLO11n-cls Architecture:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Layer    From   Params   Module                      Arguments
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  0        -1      464   Conv                        [3, 16, 3, 2]
  1        -1    4,672   Conv                        [16, 32, 3, 2]
  2        -1    6,640   C3k2                        [32, 64, 1, False, 0.25]
  3        -1   36,992   Conv                        [64, 64, 3, 2]
  4        -1   26,080   C3k2                        [64, 128, 1, False, 0.25]
  5        -1  147,712   Conv                        [128, 128, 3, 2]
  6        -1   87,040   C3k2                        [128, 128, 1, True]
  7        -1  295,424   Conv                        [128, 256, 3, 2]
  8        -1  346,112   C3k2                        [256, 256, 1, True]
  9        -1  249,728   C2PSA                       [256, 256, 1]
 10        -1  332,802   Classify                    [256, 2]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: 47 layers, 1,533,666 parameters, 3.3 GFLOPs
```

### 5.2 CÃ¡c thÃ nh pháº§n chÃ­nh

#### Conv Layer
- Convolution + BatchNorm + SiLU activation
- Stride 2 Ä‘á»ƒ downsampling

#### C3k2 Block
- CSP Bottleneck vá»›i 2 convolutions
- Feature reuse vÃ  gradient flow

#### C2PSA (Polarized Self-Attention)
- Self-attention mechanism
- Capture long-range dependencies

#### Classify Head
- Global Average Pooling
- Linear layer: 256 â†’ 2 classes

### 5.3 Hyperparameters Training

```yaml
# Optimizer
optimizer: auto         # Tá»± Ä‘á»™ng chá»n (AdamW)
lr0: 0.01               # Learning rate ban Ä‘áº§u
lrf: 0.01               # Final LR = lr0 * lrf
momentum: 0.937         # Momentum for SGD
weight_decay: 0.0005    # L2 regularization

# Training
epochs: 30
batch: 32
warmup_epochs: 3.0
warmup_momentum: 0.8
amp: true               # Automatic Mixed Precision
```

---

## 6. Káº¾T QUáº¢ TRAINING

### 6.1 Dataset

| Táº­p | Sá»‘ áº£nh | Fire | Non-Fire |
|-----|--------|------|----------|
| Train | 3,680* | ~1,840 | ~1,840 |
| Val | 929* | ~465 | ~465 |
| Test | 50 | 25 | 25 |

*Sau khi loáº¡i bá» áº£nh lá»—i (320 corrupt trong train, 71 corrupt trong val)

### 6.2 Training Progress

| Epoch | Loss | Top-1 Accuracy |
|-------|------|----------------|
| 1 | 0.225 | 95.9% |
| 5 | 0.144 | 97.4% |
| 10 | 0.090 | 98.1% |
| 15 | 0.057 | 98.4% |
| 20 | 0.040 | 98.5% |
| 23 | 0.035 | **99.2%** |
| 30 | 0.019 | 98.9% |

### 6.3 Káº¿t quáº£ cuá»‘i cÃ¹ng

| Metric | Validation | Test |
|--------|------------|------|
| **Top-1 Accuracy** | 99.2% | 98.0% |
| **Top-5 Accuracy** | 100% | 100% |
| **Inference Time** | 0.6ms | 10.6ms |

### 6.4 Training Time

- **Total:** 0.116 hours (~7 minutes)
- **GPU:** NVIDIA GeForce RTX 3070 Laptop (8GB)
- **Speed:** ~12s per epoch

---

## 7. á»¨NG Dá»¤NG WEB

### 7.1 Backend API (FastAPI)

**Endpoints:**

| Method | Endpoint | MÃ´ táº£ |
|--------|----------|-------|
| GET | `/api/health` | Kiá»ƒm tra tráº¡ng thÃ¡i |
| POST | `/api/detect/image` | PhÃ¡t hiá»‡n trong áº£nh |
| POST | `/api/detect/video` | PhÃ¡t hiá»‡n trong video |
| WS | `/api/ws/stream` | WebSocket streaming |

**VÃ­ dá»¥ Response:**
```json
{
    "prediction": "FIRE",
    "confidence": 0.9856,
    "processing_time": 0.012
}
```

### 7.2 Frontend (Streamlit)

**Chá»©c nÄƒng:**
- Upload áº£nh/video
- Hiá»ƒn thá»‹ káº¿t quáº£ real-time
- WebSocket streaming cho video
- Dashboard thá»‘ng kÃª

### 7.3 WebSocket Streaming

**Lá»£i Ã­ch so vá»›i HTTP:**
- Äá»™ trá»… tháº¥p (~100ms/frame vs hÃ ng giÃ¢y)
- Persistent connection
- Bidirectional communication

**Protocol:**
```json
// Client â†’ Server
{"type": "start", "video_path": "path/to/video.mp4"}
{"type": "frame", "data": "base64_image"}
{"type": "stop"}

// Server â†’ Client  
{"type": "frame", "prediction": "FIRE", "confidence": 0.95}
{"type": "complete", "total_frames": 100, "fire_frames": 23}
```

---

## 8. Káº¾T LUáº¬N

### 8.1 Äáº¡t Ä‘Æ°á»£c

âœ… XÃ¢y dá»±ng pipeline xá»­ lÃ½ áº£nh hoÃ n chá»‰nh
- Khá»­ nhiá»…u vá»›i Non-Local Means
- CÃ¢n báº±ng tráº¯ng vá»›i Gray World
- TÄƒng contrast vá»›i CLAHE

âœ… Train model YOLO11 Ä‘áº¡t **99.2% accuracy**
- Sá»­ dá»¥ng data augmentation hiá»‡u quáº£
- Training nhanh (~7 phÃºt)

âœ… á»¨ng dá»¥ng web real-time
- FastAPI backend
- Streamlit frontend
- WebSocket streaming

### 8.2 Háº¡n cháº¿

âš ï¸ Dataset cÃ³ nhiá»u áº£nh lá»—i (~8%)
âš ï¸ ChÆ°a test vá»›i video thá»±c táº¿
âš ï¸ ChÆ°a cÃ³ smoke detection riÃªng

### 8.3 HÆ°á»›ng phÃ¡t triá»ƒn

- Má»Ÿ rá»™ng sang detection (bounding box)
- ThÃªm class Smoke
- TÃ­ch há»£p camera thá»±c
- Deploy lÃªn cloud

---

## ğŸ“š TÃ€I LIá»†U THAM KHáº¢O

1. Ultralytics YOLO Documentation: https://docs.ultralytics.com
2. OpenCV Documentation: https://docs.opencv.org
3. "Non-Local Means Denoising" - Buades et al., 2005
4. "CLAHE" - Zuiderveld, 1994
5. "RandAugment" - Cubuk et al., 2020

---

*Report Ä‘Æ°á»£c táº¡o tá»± Ä‘á»™ng bá»Ÿi há»‡ thá»‘ng*
