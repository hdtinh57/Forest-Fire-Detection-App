# üî• Forest Fire Detection App

·ª®ng d·ª•ng ph√°t hi·ªán ch√°y r·ª´ng s·ª≠ d·ª•ng model YOLO11 Classification v·ªõi WebSocket streaming cho x·ª≠ l√Ω video real-time.

## ‚ú® Features

- **üñºÔ∏è Image Detection**: Upload ·∫£nh v√† ph√°t hi·ªán l·ª≠a v·ªõi ƒë·ªô ch√≠nh x√°c 99%
- **üé¨ Video Detection**: Ph√¢n t√≠ch video qua HTTP ho·∫∑c WebSocket
- **‚ö° WebSocket Streaming**: X·ª≠ l√Ω video real-time v·ªõi ƒë·ªô tr·ªÖ th·∫•p
- **üîß Image Preprocessing**: Kh·ª≠ nhi·ªÖu, CLAHE, c√¢n b·∫±ng tr·∫Øng

## üìÇ Project Structure

```
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ detection.py         # REST API endpoints
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ websocket.py         # WebSocket streaming
‚îÇ   ‚îú‚îÄ‚îÄ schemas/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ detection.py         # Pydantic models
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ detection.py         # YOLO11 inference
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py     # Image preprocessing
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ websocket_stream.py  # WebSocket service
‚îÇ   ‚îú‚îÄ‚îÄ main.py                  # FastAPI app
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ app.py                   # Streamlit UI
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ src/                         # Source scripts
‚îî‚îÄ‚îÄ weights/
    ‚îî‚îÄ‚îÄ best.pt                  # Trained YOLO11 model
```


## üöÄ Quick Start

### 1. Install Dependencies

```bash
# Backend
cd backend
pip install -r requirements.txt

# Frontend
cd ../frontend
pip install -r requirements.txt
```

### 2. Run Backend (FastAPI)

```bash
cd ../backend
uvicorn main:app --reload --port 8000
```

API s·∫Ω ch·∫°y t·∫°i: http://localhost:8000

Swagger Docs: http://localhost:8000/docs

### 3. Run Frontend (Streamlit)

```bash
cd frontend
streamlit run app.py
```

Frontend s·∫Ω m·ªü t·∫°i: http://localhost:8501

## üì∏ Usage

1. **Image Detection**: Upload ·∫£nh JPG/PNG ‚Üí Nh·∫≠n k·∫øt qu·∫£ FIRE/NON-FIRE
2. **Video Detection**: Upload video MP4/AVI ‚Üí Ph√¢n t√≠ch t·ª´ng frame

## üîå API Endpoints

### REST API

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/api/health` | Health check |
| POST | `/api/detect/image` | Detect fire in image |
| POST | `/api/detect/video` | Detect fire in video (sync) |

### WebSocket API

| Endpoint | Description |
|----------|-------------|
| `ws://localhost:8000/api/ws/stream` | Real-time video streaming |

#### WebSocket Protocol

**Upload video tr∆∞·ªõc:**
```http
POST /api/ws/upload-and-stream
Content-Type: multipart/form-data

Response: {"video_path": "/tmp/video123.mp4"}
```

**K·∫øt n·ªëi WebSocket v√† g·ª≠i l·ªánh:**
```javascript
const ws = new WebSocket('ws://localhost:8000/api/ws/stream');

// 1. B·∫Øt ƒë·∫ßu x·ª≠ l√Ω video
ws.send(JSON.stringify({
    type: 'start',
    video_path: '/tmp/video123.mp4',
    frame_skip: 2  // X·ª≠ l√Ω m·ªói 2 frame
}));

// 2. Nh·∫≠n k·∫øt qu·∫£ t·ª´ng frame
ws.onmessage = (event) => {
    const data = JSON.parse(event.data);
    
    if (data.type === 'video_info') {
        console.log('Total frames:', data.total_frames);
    }
    
    if (data.type === 'frame') {
        console.log('Frame:', data.frame_number);
        console.log('Prediction:', data.prediction);  // FIRE or NON-FIRE
        console.log('Confidence:', data.confidence);
        // data.frame = base64 encoded image
    }
    
    if (data.type === 'complete') {
        console.log('Fire percentage:', data.fire_percentage);
    }
};

// 3. D·ª´ng x·ª≠ l√Ω
ws.send(JSON.stringify({ type: 'stop' }));
```

#### X·ª≠ l√Ω frame ƒë∆°n l·∫ª

```javascript
// G·ª≠i 1 frame ƒë·ªÉ detect
ws.send(JSON.stringify({
    type: 'frame',
    data: base64ImageData  // Base64 encoded image
}));

// Nh·∫≠n k·∫øt qu·∫£
ws.onmessage = (event) => {
    const result = JSON.parse(event.data);
    // result.prediction: "FIRE" or "NON-FIRE"
    // result.confidence: 0.0 - 1.0
    // result.processing_time_ms: th·ªùi gian x·ª≠ l√Ω (ms)
    // result.frame: base64 processed image
};
```

## üñºÔ∏è Image Preprocessing

H·ªá th·ªëng √°p d·ª•ng c√°c k·ªπ thu·∫≠t x·ª≠ l√Ω ·∫£nh tr∆∞·ªõc khi ƒë∆∞a v√†o model:

| Technique | Description |
|-----------|-------------|
| **Bilateral Filter** | Kh·ª≠ nhi·ªÖu gi·ªØ c·∫°nh |
| **Saturation Boost** | TƒÉng ƒë·ªô b√£o h√≤a m√†u l·ª≠a |
| **CLAHE** | C·∫£i thi·ªán contrast c·ª•c b·ªô |

C√≥ th·ªÉ t·∫Øt preprocessing qua API:
```http
POST /api/detect/image?enable_preprocessing=false
```

## üìä Output

- **FIRE** üî•: Ph√°t hi·ªán c√≥ l·ª≠a (confidence: 0-100%)
- **NON-FIRE** ‚úÖ: Kh√¥ng c√≥ l·ª≠a

## üõ†Ô∏è Technology Stack

| Component | Technology |
|-----------|------------|
| **Backend** | FastAPI, Uvicorn |
| **Frontend** | Streamlit |
| **ML Model** | YOLO11 Classification |
| **WebSocket** | FastAPI WebSocket |
| **Image Processing** | OpenCV, NumPy |

## üìà Performance

| Metric | Value |
|--------|-------|
| Model Accuracy | 99.2% |
| Inference Time | ~10ms/image |
| WebSocket Latency | ~100ms/frame |
